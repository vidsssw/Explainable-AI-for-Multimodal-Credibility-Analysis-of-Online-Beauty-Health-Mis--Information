{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Quality_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPgAQgdDWNAL"
      },
      "source": [
        "!pip install opencv-python>=3.4.2.17\n",
        "!pip install libsvm>=3.23.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbSr8WzmWOOb"
      },
      "source": [
        "import collections\n",
        "from itertools import chain\n",
        "import urllib.request as request\n",
        "import pickle \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import scipy.signal as signal\n",
        "import scipy.special as special\n",
        "import scipy.optimize as optimize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "import cv2\n",
        "\n",
        "from libsvm import svmutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0LUdTKlWVLR"
      },
      "source": [
        "def normalize_kernel(kernel):\n",
        "    return kernel / np.sum(kernel)\n",
        "\n",
        "def gaussian_kernel2d(n, sigma):\n",
        "    Y, X = np.indices((n, n)) - int(n/2)\n",
        "    gaussian_kernel = 1 / (2 * np.pi * sigma ** 2) * np.exp(-(X ** 2 + Y ** 2) / (2 * sigma ** 2)) \n",
        "    return normalize_kernel(gaussian_kernel)\n",
        "\n",
        "def local_mean(image, kernel):\n",
        "    return signal.convolve2d(image, kernel, 'same')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC49t8y6WYU8"
      },
      "source": [
        "def local_deviation(image, local_mean, kernel):\n",
        "    \"Vectorized approximation of local deviation\"\n",
        "    sigma = image ** 2\n",
        "    sigma = signal.convolve2d(sigma, kernel, 'same')\n",
        "    return np.sqrt(np.abs(local_mean ** 2 - sigma))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9y_zwpeWbnj"
      },
      "source": [
        "def calculate_mscn_coefficients(image, kernel_size=6, sigma=7/6):\n",
        "    C = 1/255\n",
        "    kernel = gaussian_kernel2d(kernel_size, sigma=sigma)\n",
        "    local_mean = signal.convolve2d(image, kernel, 'same')\n",
        "    local_var = local_deviation(image, local_mean, kernel)\n",
        "    \n",
        "    return (image - local_mean) / (local_var + C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQXfrDALWffJ"
      },
      "source": [
        "def generalized_gaussian_dist(x, alpha, sigma):\n",
        "    beta = sigma * np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
        "    \n",
        "    coefficient = alpha / (2 * beta() * special.gamma(1 / alpha))\n",
        "    return coefficient * np.exp(-(np.abs(x) / beta) ** alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwTFwbovWio0"
      },
      "source": [
        "def calculate_pair_product_coefficients(mscn_coefficients):\n",
        "    return collections.OrderedDict({\n",
        "        'mscn': mscn_coefficients,\n",
        "        'horizontal': mscn_coefficients[:, :-1] * mscn_coefficients[:, 1:],\n",
        "        'vertical': mscn_coefficients[:-1, :] * mscn_coefficients[1:, :],\n",
        "        'main_diagonal': mscn_coefficients[:-1, :-1] * mscn_coefficients[1:, 1:],\n",
        "        'secondary_diagonal': mscn_coefficients[1:, :-1] * mscn_coefficients[:-1, 1:]\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyrcwPplWmFX"
      },
      "source": [
        "def asymmetric_generalized_gaussian(x, nu, sigma_l, sigma_r):\n",
        "    def beta(sigma):\n",
        "        return sigma * np.sqrt(special.gamma(1 / nu) / special.gamma(3 / nu))\n",
        "    \n",
        "    coefficient = nu / ((beta(sigma_l) + beta(sigma_r)) * special.gamma(1 / nu))\n",
        "    f = lambda x, sigma: coefficient * np.exp(-(x / beta(sigma)) ** nu)\n",
        "        \n",
        "    return np.where(x < 0, f(-x, sigma_l), f(x, sigma_r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECbfiixKWpIr"
      },
      "source": [
        "def asymmetric_generalized_gaussian_fit(x):\n",
        "    def estimate_phi(alpha):\n",
        "        numerator = special.gamma(2 / alpha) ** 2\n",
        "        denominator = special.gamma(1 / alpha) * special.gamma(3 / alpha)\n",
        "        return numerator / denominator\n",
        "\n",
        "    def estimate_r_hat(x):\n",
        "        size = np.prod(x.shape)\n",
        "        return (np.sum(np.abs(x)) / size) ** 2 / (np.sum(x ** 2) / size)\n",
        "\n",
        "    def estimate_R_hat(r_hat, gamma):\n",
        "        numerator = (gamma ** 3 + 1) * (gamma + 1)\n",
        "        denominator = (gamma ** 2 + 1) ** 2\n",
        "        return r_hat * numerator / denominator\n",
        "\n",
        "    def mean_squares_sum(x, filter = lambda z: z == z):\n",
        "        filtered_values = x[filter(x)]\n",
        "        squares_sum = np.sum(filtered_values ** 2)\n",
        "        return squares_sum / ((filtered_values.shape))\n",
        "    def estimate_gamma(x):\n",
        "        left_squares = mean_squares_sum(x, lambda z: z < 0)\n",
        "        right_squares = mean_squares_sum(x, lambda z: z >= 0)\n",
        "\n",
        "        return np.sqrt(left_squares) / np.sqrt(right_squares)\n",
        "\n",
        "    def estimate_alpha(x):\n",
        "        r_hat = estimate_r_hat(x)\n",
        "        gamma = estimate_gamma(x)\n",
        "        R_hat = estimate_R_hat(r_hat, gamma)\n",
        "\n",
        "        solution = optimize.root(lambda z: estimate_phi(z) - R_hat, [0.2]).x\n",
        "\n",
        "        return solution[0]\n",
        "\n",
        "    def estimate_sigma(x, alpha, filter = lambda z: z < 0):\n",
        "        return np.sqrt(mean_squares_sum(x, filter))\n",
        "    \n",
        "    def estimate_mean(alpha, sigma_l, sigma_r):\n",
        "        return (sigma_r - sigma_l) * constant * (special.gamma(2 / alpha) / special.gamma(1 / alpha))\n",
        "    \n",
        "    alpha = estimate_alpha(x)\n",
        "    sigma_l = estimate_sigma(x, alpha, lambda z: z < 0)\n",
        "    sigma_r = estimate_sigma(x, alpha, lambda z: z >= 0)\n",
        "    \n",
        "    constant = np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
        "    mean = estimate_mean(alpha, sigma_l, sigma_r)\n",
        "    \n",
        "    return alpha, mean, sigma_l, sigma_r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wliu0P7oW9pS"
      },
      "source": [
        "def calculate_brisque_features(image, kernel_size=7, sigma=7/6):\n",
        "    def calculate_features(coefficients_name, coefficients, accum=np.array([])):\n",
        "        alpha, mean, sigma_l, sigma_r = asymmetric_generalized_gaussian_fit(coefficients)\n",
        "\n",
        "        if coefficients_name == 'mscn':\n",
        "            var = (sigma_l ** 2 + sigma_r ** 2) / 2\n",
        "            return [alpha, var]\n",
        "        \n",
        "        return [alpha, mean, sigma_l ** 2, sigma_r ** 2]\n",
        "    \n",
        "    mscn_coefficients = calculate_mscn_coefficients(image, kernel_size, sigma)\n",
        "    coefficients = calculate_pair_product_coefficients(mscn_coefficients)\n",
        "    \n",
        "    features = [calculate_features(name, coeff) for name, coeff in coefficients.items()]\n",
        "    flatten_features = list(chain.from_iterable(features))\n",
        "    return np.array(flatten_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6BlH4CzXw9x",
        "outputId": "48e5fdef-8b99-4730-8c0f-68c87e984379"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtzrAV1BXkBk"
      },
      "source": [
        "Testinggg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF374zqTXCGO",
        "outputId": "01f4cdc2-4568-4c0c-8f96-bdcf0ea91284"
      },
      "source": [
        "from imutils import paths\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "data_paths = \"/content/drive/My Drive/Test_Images/test\"\n",
        "imagePaths = list(paths.list_images(data_paths))\n",
        "ans = []\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for i in imagePaths:\n",
        "  image = skimage.io.imread(i)\n",
        "  gray_image = skimage.color.rgb2gray(image)\n",
        "  \n",
        "  mscn_coefficients = calculate_mscn_coefficients(gray_image, 7, 7/6)\n",
        "  coefficients = calculate_pair_product_coefficients(mscn_coefficients)\n",
        "  brisque_features = calculate_brisque_features(gray_image, kernel_size=7, sigma=7/6)\n",
        "  downscaled_image = cv2.resize(gray_image, None, fx=1/2, fy=1/2, interpolation = cv2.INTER_CUBIC)\n",
        "  downscale_brisque_features = calculate_brisque_features(downscaled_image, kernel_size=7, sigma=7/6)\n",
        "  temp = np.concatenate((brisque_features, downscale_brisque_features))\n",
        "\n",
        "  ans.append(temp)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_ARgCSJYimm"
      },
      "source": [
        "def scale_features(features):\n",
        "    with open('/content/normalize.pickle', 'rb') as handle:\n",
        "        scale_params = pickle.load(handle)\n",
        "    \n",
        "    min_ = np.array(scale_params['min_'])\n",
        "    max_ = np.array(scale_params['max_'])\n",
        "    \n",
        "    return -1 + (2.0 / (max_ - min_) * (features - min_))\n",
        "\n",
        "def calculate_image_quality_score(brisque_features):\n",
        "    model = svmutil.svm_load_model('/content/brisque_svm.txt')\n",
        "    scaled_brisque_features = scale_features(brisque_features)\n",
        "    \n",
        "    x, idx = svmutil.gen_svm_nodearray(\n",
        "        scaled_brisque_features,\n",
        "        isKernel=(model.param.kernel_type == svmutil.PRECOMPUTED))\n",
        "    \n",
        "    nr_classifier = 1\n",
        "    prob_estimates = (svmutil.c_double * nr_classifier)()\n",
        "    \n",
        "    return svmutil.libsvm.svm_predict_probability(model, x, prob_estimates)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxtaEwK2YjeN"
      },
      "source": [
        "scores = []\n",
        "for i in ans:\n",
        "  scores.append(round(calculate_image_quality_score(i)/10,ndigits=2))\n",
        "\n",
        "df['Image_Quality_Score']=scores"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWILR3j3l-va"
      },
      "source": [
        "df.to_csv(r'/content/qualityscore.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}